{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6549af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "!pip install -U datasets tiktoken tqdm numpy torch matplotlib huggingface_hub\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from contextlib import nullcontext\n",
    "from dataclasses import dataclass, field\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import tiktoken\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configs file\n",
    "from dataclasses import dataclass, field\n",
    "import os\n",
    "import torch\n",
    "@dataclass\n",
    "class SLMConfig:\n",
    "    block_size: int = 256\n",
    "    vocab_size: int = 50257     \n",
    "    n_layer: int = 12           \n",
    "    n_head: int = 12           \n",
    "    n_embd: int = 768          \n",
    "    dropout: float = 0.1\n",
    "    bias: bool = False\n",
    "    batch_size: int = 8         \n",
    "    gradient_accumulation_steps: int = 4 \n",
    "    max_iters: int = 100000     \n",
    "    eval_interval: int = 1000   \n",
    "    eval_iters: int = 200\n",
    "    learning_rate: float = 3e-4 \n",
    "    weight_decay: float = 0.1\n",
    "    beta1: float = 0.9\n",
    "    beta2: float = 0.95\n",
    "    grad_clip: float = 1.0\n",
    "    warmup_iters: int = 2000    \n",
    "    lr_decay_iters: int = 100000\n",
    "    min_lr: float = 3e-5        \n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    dtype: str = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "    compile: bool = True\n",
    "    data_dir: str = 'data_combined'\n",
    "    num_proc: int = 8\n",
    "    total_batches: int = 1024 \n",
    "    out_dir: str = 'out_v3' \n",
    "    best_model_name: str = 'best_model_v3.pt'\n",
    "    local_pretrained_path: str = \"\" \n",
    "\n",
    "config = SLMConfig()\n",
    "config.lr_decay_iters = config.max_iters\n",
    "\n",
    "os.makedirs(config.out_dir, exist_ok=True)\n",
    "os.makedirs(config.data_dir, exist_ok=True)\n",
    "best_model_path = os.path.join(config.out_dir, config.best_model_name)\n",
    "\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[config.dtype]\n",
    "torch.set_default_dtype(ptdtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
